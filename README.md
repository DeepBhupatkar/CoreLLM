# CoreLLM

**Your on-device AI, built the Apple way.**  
A native local LLM experience for macOS, iOS, and iPadOS ‚Äî powered by Swift, SwiftUI, and MLX.

---

## üß† What is CoreLLM?

CoreLLM is a fully native Swift application that brings large language model (LLM) capabilities directly to your Apple devices ‚Äî no cloud required.

Built with [MLX](https://github.com/DeepBhupatkar/mlx-swift-examples) and SwiftUI, it offers a seamless, fast, and private AI experience across macOS, iOS, and iPadOS.

Whether you're running queries, generating content, or experimenting with prompts, CoreLLM puts the power of language models *in your hands ‚Äî locally.*

---

## üîí Key Features

- üñ•Ô∏è **Cross-platform**: Available for Mac, iPhone, and iPad.
- ‚ö° **Fast & Local**: All inference is done on-device ‚Äî no internet or server needed.
- üß± **Powered by MLX**: Optimized for Apple Silicon with Apple‚Äôs machine learning stack.
- üßë‚Äçüíª **Built in Swift**: Clean architecture with SwiftUI and native performance.
- ‚ú® **Chat-style UI**: Minimal and modern experience to interact with your LLM.
- **Supported Platforms**: macOS (Apple Silicon), iOS, iPadOS

---

## üì¶ Getting Started

> ‚ö†Ô∏è You‚Äôll need Xcode 15+, a Mac with Apple Silicon, and the MLX framework installed.

```bash
git clone https://github.com/yourusername/CoreLLM.git
cd CoreLLM
open CoreLLM.xcodeproj
